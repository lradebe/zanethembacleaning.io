# Zanethemba Website - Automated Test Suite

Comprehensive automated testing suite for the Zanethemba Cleaning Services website using Pytest and Playwright.

## ğŸ“‹ Overview

This test suite provides:
- âœ… **Happy Path Tests** - Core functionality and user flows
- âŒ **Negative Tests** - Edge cases, invalid inputs, error handling
- âš¡ **Performance Tests** - Load times, navigation speed, carousel performance
- ğŸ“Š **Code Coverage** - Detailed coverage reports with visual dashboard
- ğŸ“ **Structured Logging** - INFO and ERROR level logs (console shows only errors)
- ğŸ¨ **Visual Dashboard** - Beautiful web interface matching Zanethemba's styling

## ğŸš€ Quick Start

### Installation

```bash
# Install dependencies
pip install -r requirements.txt

# Install Playwright browsers
python3 -m playwright install chromium
```

### Running Tests

```bash
# Run all tests
python3 run_tests.py

# Or use pytest directly
python3 -m pytest
```

### View Dashboard

```bash
# Start the dashboard server
python3 dashboard/app.py

# Open in browser
# http://localhost:5000
```

## ğŸ“ Project Structure

```
zanethemba_tests/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_navigation.py    # Navigation & UI tests
â”‚   â”œâ”€â”€ test_content.py        # Content & element tests
â”‚   â”œâ”€â”€ test_forms.py          # Form & interaction tests
â”‚   â”œâ”€â”€ test_performance.py    # Performance benchmarks
â”‚   â””â”€â”€ test_negative.py       # Negative/edge case tests
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ app.py                 # Flask dashboard app
â”‚   â”œâ”€â”€ templates/             # HTML templates
â”‚   â”‚   â”œâ”€â”€ base.html
â”‚   â”‚   â”œâ”€â”€ index.html
â”‚   â”‚   â”œâ”€â”€ tests.html
â”‚   â”‚   â”œâ”€â”€ coverage.html
â”‚   â”‚   â””â”€â”€ logs.html
â”‚   â””â”€â”€ static/                # Static assets
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ pytest_report.html     # HTML test report
â”‚   â”œâ”€â”€ coverage/              # Coverage HTML report
â”‚   â”œâ”€â”€ test_results.json      # Test results JSON
â”‚   â””â”€â”€ coverage.json          # Coverage JSON
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ test_execution_*.log   # Timestamped log files
â”œâ”€â”€ conftest.py                # Pytest configuration
â”œâ”€â”€ pytest.ini                 # Pytest settings
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ run_tests.py              # Test runner script
â””â”€â”€ README.md                  # This file
```

## ğŸ§ª Test Categories

### Navigation Tests (`test_navigation.py`)
- Splash screen behavior
- Navigation links functionality
- Logo and brand name display
- Active link styling
- Mobile hamburger menu
- Footer navigation

**Markers:** `@pytest.mark.smoke`, `@pytest.mark.regression`

### Content Tests (`test_content.py`)
- Hero section content
- CTA buttons
- Carousel functionality
- Trust bar icons
- Services grid
- Stats section
- B-BBEE badges
- Responsive design

**Markers:** `@pytest.mark.smoke`, `@pytest.mark.regression`

### Form Tests (`test_forms.py`)
- Contact form validation
- Required field enforcement
- Email format validation
- Form submission
- CTA button navigation
- External link protocols

**Markers:** `@pytest.mark.smoke`, `@pytest.mark.regression`, `@pytest.mark.negative`

### Performance Tests (`test_performance.py`)
- Initial page load time (< 3s target)
- Full page load time (< 6s with splash)
- Navigation speed (< 1s target)
- Carousel rotation smoothness
- Form interaction responsiveness
- Mobile menu animation speed
- Resource loading (embedded images)
- Memory stability

**Markers:** `@pytest.mark.performance`

### Negative Tests (`test_negative.py`)
- Invalid email format
- Empty form submission
- Extremely long inputs
- Special characters & XSS attempts
- SQL injection attempts
- Rapid navigation clicks
- Double-click handling
- Mobile edge cases
- Carousel edge cases
- Browser compatibility

**Markers:** `@pytest.mark.negative`

## ğŸ“Š Dashboard Features

### Overview Page
- Test execution summary (total, passed, failed)
- Coverage percentage with progress bar
- Duration statistics
- Quick links to detailed views

### Test Cases Page
- Complete list of all test cases
- Pass/fail status with badges
- Execution duration per test
- Filterable by status (All, Passed, Failed, Skipped)

### Coverage Page
- Overall coverage percentage
- Covered vs total lines
- File-by-file breakdown
- Link to detailed HTML coverage report

### Logs Page
- All INFO and ERROR logs
- Timestamped entries
- Filterable by level
- Searchable log viewer

## ğŸ¨ Dashboard Styling

The dashboard matches Zanethemba's brand identity:
- **Colors:** Crimson red (#8B1A1A), Green (#4A7C2F), Cream (#FDFCF8)
- **Typography:** Cormorant Garamond (headings), DM Sans (body)
- **Design:** Clean, professional, consistent with main website

## ğŸ“ Logging

### Log Levels
- **INFO:** Test execution flow, navigation events, assertions
- **ERROR:** Test failures, exceptions, critical issues

### Console Output
- âŒ **Errors only** - Only ERROR level logs appear in terminal
- âœ… **Success indicators** - Pass/fail summary at end
- ğŸ“Š **Report locations** - Paths to generated reports

### Log Files
- ğŸ“‚ **Location:** `logs/test_execution_YYYYMMDD_HHMMSS.log`
- ğŸ“„ **Format:** `YYYY-MM-DD HH:MM:SS [LEVEL] module - message`
- ğŸ’¾ **Retention:** All INFO and ERROR logs saved to file

## ğŸ”§ Configuration

### pytest.ini
- Test discovery patterns
- Coverage settings
- Report generation
- Log file configuration
- Pytest markers

### conftest.py
- Browser fixtures (desktop, mobile, tablet)
- Logging configuration
- Test lifecycle hooks
- Custom fixtures

## ğŸ“ˆ Coverage Reporting

Multiple coverage report formats:
- **HTML:** Interactive line-by-line coverage (`reports/coverage/index.html`)
- **JSON:** Machine-readable data (`reports/coverage.json`)
- **Terminal:** Summary in console (only if errors)

## ğŸ¯ Test Execution Options

```bash
# Run specific test file
pytest tests/test_navigation.py

# Run tests by marker
pytest -m smoke                # Quick smoke tests
pytest -m regression          # Full regression suite
pytest -m performance         # Performance tests only
pytest -m negative           # Negative tests only

# Run with verbose output (errors only to console)
pytest -v

# Run specific test
pytest tests/test_forms.py::TestContactForm::test_form_submission_happy_path

# Run in parallel (install pytest-xdist first)
pytest -n auto
```

## ğŸ› Debugging

### View detailed logs
```bash
# View latest log file
cat logs/test_execution_*.log | tail -100

# Filter ERROR logs only
grep ERROR logs/test_execution_*.log

# Real-time log following
tail -f logs/test_execution_*.log
```

### Run tests in headed mode (see browser)
Edit `conftest.py` and change `headless: True` to `headless: False`

### Generate trace for failed tests
```bash
pytest --tracing retain-on-failure
```

## ğŸ“š Dependencies

- **pytest** - Testing framework
- **playwright** - Browser automation
- **pytest-playwright** - Playwright integration
- **pytest-cov** - Coverage plugin
- **pytest-html** - HTML reports
- **pytest-json-report** - JSON reports
- **flask** - Dashboard web server
- **jinja2** - Template engine

## âœ… Success Criteria

A successful test run meets:
- âœ“ All smoke tests pass
- âœ“ 95%+ regression tests pass
- âœ“ No performance tests fail
- âœ“ Page load < 3 seconds
- âœ“ Navigation < 1 second
- âœ“ Code coverage > 80% (if applicable)
- âœ“ No ERROR logs (except expected negative test errors)

## ğŸ¤ Contributing

When adding new tests:
1. Place in appropriate test file by category
2. Add proper `@pytest.mark` decorators
3. Include INFO logging for test flow
4. Use ERROR logging for failures
5. Follow existing naming conventions
6. Update this README if adding new categories

## ğŸ“ Support

For issues or questions about the test suite:
- Review logs in `logs/` directory
- Check dashboard at http://localhost:5000
- Review pytest.ini configuration
- Examine conftest.py fixtures

---

**Zanethemba Cleaning Services (Pty) Ltd**  
*"Bringing Hope Through Cleanliness"*
